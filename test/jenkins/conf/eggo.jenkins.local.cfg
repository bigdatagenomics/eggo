; Eggo "global" config

[dfs]
; The location of the result data sets in the targeted distributed file system
; (dfs). Currently supports S3 (s3n://), HDFS (hdfs://), and local (file://)
; targets. The specified URL will be the root of the eggo directory structure
; (see spec)
dfs_root_url: file:///tmp/eggo_dfs

; Path to stage the raw input data on the target distributed fs
; raw data ends up in <dfs_raw_data_url>/<dataset_name>
dfs_raw_data_url: %(dfs_root_url)s/raw

; Path to store tmp/intermediate data in the target distributed fs
; tmp data ends up in <dfs_root_url>/<dfs_tmp_data_dir>/<dataset_name>/<random_id>
dfs_tmp_data_url: %(dfs_root_url)s/tmp


[execution]
; The context for execution. Possible values are spark_ec2, director, local.
; There are config sections for each of the possible values.
context: local

; Random identifier that is generated on module load.  Do not set this manually
random_id:


[versions]
eggo_fork: bigdatagenomics
eggo_branch: master

adam_fork: bigdatagenomics
adam_branch: master

maven: 3.2.5


[client_env]
; Can be overridden by setting SPARK_HOME env var
spark_home: /tmp/eggo_work/spark-1.3.1-bin-hadoop2.6


[worker_env]
; directory on worker machines where we can write to, including staging
; temporary large data files; it will be created with mkdir -p
work_path: /tmp/eggo_work

; path on worker machines where this file is copied to
eggo_config_path: %(work_path)s/eggo.cfg

; path on worker machines to the luigi config file
luigi_config_path: %(work_path)s/luigi.cfg

; equiv to SPARK_HOME on the worker environment
spark_home: %(work_path)s/spark-1.3.1-bin-hadoop2.6

; should have a bin subdir where the hadoop binary is located
hadoop_home: %(work_path)s/hadoop-2.6.0

; path to the hadoop streaming jar
streaming_jar: %(hadoop_home)s/share/hadoop/tools/lib/hadoop-streaming-2.6.0.jar

; string compatible with the --master option to spark-submitthis string must
; evaluate correctly in a shell environment
; spark_master: spark://$(curl http://169.254.169.254/latest/meta-data/public-hostname):7077
spark_master: local[2]

; path on worker machines where adam is built/installed
adam_home: %(work_path)s/adam

; path on worker machines where the eggo repo is checked out
eggo_home: %(work_path)s/eggo

; memory allocated to spark on each slave. This is a configuration parameter for spark-submit
executor_memory: 55G


[aws]
; These can be set/overridden by setting corresponding local env vars (in ALL_CAPS)
aws_access_key_id:
aws_secret_access_key:
ec2_key_pair:
ec2_private_key_file:


[spark_ec2]
; Spark EC2 scripts configuration
; Path to local Spark installation
region: us-east-1
; set this to a valid value to specify an availability zone:
availability_zone: us-east-1a
;instance_type: r3.2xlarge
instance_type: r3.large
;instance_type: m1.large
num_slaves: 2
user: root
stack_name: bdg-eggo-test


[director]
; Cloudera Director configuration
; TODO: add docs to these options
region: us-east-1
; set this to a valid value to specify an availability zone:
availability_zone:
launcher_instance_type: m3.large
launcher_ami: ami-a25415cb  ; RHEL 6.4 x86
cluster_ami: %(launcher_ami)s
stack_name: bdg-eggo-test
num_workers: 3
; the pointers to the director configs are executed relative to CWD (which may
; be the same as EGGO_HOME); set them to an absolute path if desired, or use
; "%(eggo_home)s" to access the EGGO_HOME env variable
cloudformation_template: conf/director/cfn-cloudera-us-east-1-public-subnet.template
director_conf_template: conf/director/aws.conf
